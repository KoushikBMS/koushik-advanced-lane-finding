{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffa85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27ad20",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f40fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below function is used to undistor the image by using the camera calibration parameter by reading it from the pickle file\n",
    "def undistortImage(orginal_image):\n",
    "    #load the cameara calibration values Dictionary from the pickle which was calucated in the CameraCalibration.ipynd\n",
    "    Loaded_CameraCalibrationData = pickle.load( open( \"CameraCalibrationData.p\", \"rb\" ))\n",
    "    \n",
    "    #undistort the image by using the calibration matrix and distortion coefficients in the cv2.undistort function\n",
    "    undistorted_image = cv2.undistort(orginal_image,Loaded_CameraCalibrationData[\"mtx\"] ,Loaded_CameraCalibrationData[\"dist\"], None,Loaded_CameraCalibrationData[\"mtx\"])\n",
    "    \n",
    "    return undistorted_image\n",
    "\n",
    "'''The below function is used to superimpose the detected Lane lines over the original image,\n",
    "   to achive this cv2.addWeighted function is used'''\n",
    "def weighted_img(img, initial_img, α=1, β=0.3, γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc6cc6",
   "metadata": {},
   "source": [
    "# Wrap Class\n",
    "\n",
    "The Wrap class is used to apply perspective trasnformation or inverse perspective over the provided image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87d29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrap:\n",
    "    def __init__(self):\n",
    "        #defined the Source and Destination point on the image based on which the perspective trasformation done\n",
    "        src = np.float32([[580, 450],[190,720],[1110,720],[708,450]])\n",
    "        dst = np.float32([[320,0],[320,720],[960,720],[960,0]])\n",
    "        #Calculate transform matrix for above Source and Destination point\n",
    "        self.M = cv2.getPerspectiveTransform(src, dst)\n",
    "        #Calculate inverse transform matrix for above Source and Destination point\n",
    "        self.M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    #The below fucntion is used to do perspective trasformation over the sent image\n",
    "    def perspectiveWarp(self,Image):\n",
    "        #store the image size\n",
    "        img_size = (Image.shape[1],Image.shape[0])\n",
    "        #cv2.warpPerspective function is used to apply the perspective trasformation over the image using the transform matrix(M)\n",
    "        warped = cv2.warpPerspective(Image, self.M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        return warped\n",
    "    \n",
    "    #The below fucntion is used to do inverse perspective trasformation over the sent image\n",
    "    def perspectiveWarpInv(self,Image):\n",
    "        #store the image size\n",
    "        img_size = (Image.shape[1],Image.shape[0])\n",
    "        #cv2.warpPerspective function is used to apply the inverse perspective trasformation over the image using the inverse transform matrix(M_inv)\n",
    "        warped = cv2.warpPerspective(Image, self.M_inv, img_size, flags=cv2.INTER_LINEAR)\n",
    "        return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8236e7",
   "metadata": {},
   "source": [
    "# ColourAndGradient Class\n",
    "\n",
    "The ColourAndGradient is used to apply the Colour and gradient filtering over the image to get the required pixels for the detection of the lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14295711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColourAndGradient:\n",
    "    def __init__(self,Undistored_image):\n",
    "        #store the undistored image\n",
    "        self.Image = Undistored_image\n",
    "        \n",
    "        # Convert to HLS color space\n",
    "        self.hls = cv2.cvtColor(self.Image, cv2.COLOR_RGB2HLS)\n",
    "        \n",
    "        #Separate the H,L,S channels from the converted image\n",
    "        self.h_channel = self.hls[:,:,0]\n",
    "        self.l_channel = self.hls[:,:,1]\n",
    "        self.s_channel = self.hls[:,:,2]\n",
    "                \n",
    "        #Sobel kernel size\n",
    "        self.ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "        \n",
    "        #set Thresholds used for the gradient filtering\n",
    "        self.sobel_thresh=(20, 100)\n",
    "        self.mag_thresh=(40, 100)\n",
    "        self.dir_thresh = (0.6, 1.4)\n",
    "        \n",
    "        #set Thresholds used for the Color filtering\n",
    "        self.s_thresh=115\n",
    "        self.l_thresh=40\n",
    "        self.l_thresh1=200\n",
    "        \n",
    "        #Calculate the sobel for both x and Y orientation which will be used for the filtering\n",
    "        self.sobelx = cv2.Sobel(self.l_channel, cv2.CV_64F, 1, 0,ksize = self.ksize)\n",
    "        self.sobely = cv2.Sobel(self.l_channel, cv2.CV_64F, 0, 1,ksize = self.ksize)\n",
    "        \n",
    "    #The below function is used to filter out the pixel based Gradient strength\n",
    "    def grad_threshold(self,orient = 'x'):\n",
    "        # Calculate directional gradient\n",
    "        #check the input orient\n",
    "        if orient == 'x':\n",
    "            #get the absolute value of the Sobel X gradient\n",
    "            abs_sobel = np.absolute(self.sobelx)\n",
    "        else:\n",
    "            #get the absolute value of the Sobel Y gradient\n",
    "            abs_sobel = np.absolute(self.sobely)\n",
    "        \n",
    "        #convert the abosule value image into 8-bit\n",
    "        scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "        \n",
    "        #create a similar scaled_sobel size image with zero\n",
    "        grad_binary = np.zeros_like(scaled_sobel)\n",
    "        \n",
    "        # Apply threshold and set the pixel which satisfies the condtion as 1\n",
    "        grad_binary[(scaled_sobel > self.sobel_thresh[0]) & (scaled_sobel <= self.sobel_thresh[1])] = 1\n",
    "\n",
    "        return grad_binary\n",
    "    \n",
    "    #The below function is used to filter out the pixel based magnitude of the Gradient\n",
    "    def mag_threshold(self):\n",
    "        # Calculate gradient magnitude\n",
    "        abs_sobel_xy = np.sqrt((self.sobelx**2) + (self.sobely**2))\n",
    "        \n",
    "        #convert the magnitude gradient image into 8-bit\n",
    "        scaled_sobel = np.uint8(255*abs_sobel_xy/np.max(abs_sobel_xy))\n",
    "\n",
    "        #create a similar scaled_sobel size image with zero\n",
    "        mag_binary = np.zeros_like(scaled_sobel)\n",
    "        \n",
    "        # Apply magnitude threshold and set the pixel which satisfies the condtion as 1\n",
    "        mag_binary[(scaled_sobel > self.mag_thresh[0]) & (scaled_sobel <= self.mag_thresh[1])] = 1\n",
    "\n",
    "        return mag_binary\n",
    "\n",
    "    def dir_threshold(self):\n",
    "        #get the absolute value of the Sobel X gradient\n",
    "        abs_sobel_x = np.absolute(self.sobelx)\n",
    "        \n",
    "        #get the absolute value of the Sobel Y gradient\n",
    "        abs_sobel_y = np.absolute(self.sobely)\n",
    "        \n",
    "        # Calculate gradient direction\n",
    "        dirG = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "        \n",
    "        #create a similar dirG size image with zero\n",
    "        dir_binary = np.zeros_like(dirG)\n",
    "        \n",
    "        # Apply direction threshold and set the pixel which satisfies the condtion as 1\n",
    "        dir_binary[(dirG > self.dir_thresh[0]) & (dirG < self.dir_thresh[1])] = 1\n",
    "        return dir_binary\n",
    "    \n",
    "    def ApplyColourAndGradient(self):        \n",
    "        #Apply X directional Gradient\n",
    "        gradx = self.grad_threshold(orient = 'x')\n",
    "        #Apply Y directional Gradient\n",
    "        grady = self.grad_threshold(orient = 'y')\n",
    "        #apply Magnitude of the Gradient\n",
    "        mag_binary = self.mag_threshold()\n",
    "        #Apply Direction of the Gradient\n",
    "        dir_binary = self.dir_threshold()\n",
    "\n",
    "        #create a similar gradx size image with zero\n",
    "        combined = np.zeros_like(gradx)\n",
    "        \n",
    "        #combining the all the gradient threshold filtered results\n",
    "        combined[((gradx == 1) & (grady == 1)) & ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "        #create a similar s_channel size image with zero\n",
    "        s_binary = np.zeros_like(self.s_channel)\n",
    "        \n",
    "        # Apply Color threshold for the below condition and set the pixel which satisfies the condtion as 1\n",
    "        s_binary[((self.s_channel > self.s_thresh) & (self.l_channel > self.l_thresh)) | ((self.l_channel > self.l_thresh1)) ] = 1\n",
    "\n",
    "        # Stack each channel\n",
    "        color_binary = np.zeros_like(combined)\n",
    "        \n",
    "        #combining gradient filter result and Colour filter result\n",
    "        color_binary[(combined == 1) | (s_binary==1)] = 1\n",
    "        \n",
    "        return color_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a79bb",
   "metadata": {},
   "source": [
    "# Detect Lane Line and curvature Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c7359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectLaneAndCurvature:\n",
    "    def __init__(self,WrapImage):\n",
    "        self.Image = WrapImage\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        self.ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        self.xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    def find_lane_pixels(self):\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(self.Image[self.Image.shape[0]//2:,:], axis=0)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # HYPERPARAMETERS\n",
    "        # Set the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "\n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(self.Image.shape[0]//nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = self.Image.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated later for each window in nwindows\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = self.Image.shape[0] - (window+1)*window_height\n",
    "            win_y_high = self.Image.shape[0] - window*window_height\n",
    "            #calculate the four below boundaries of the window\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "\n",
    "            ##Identify the nonzero pixels in x and y within the window ###\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            #If you found > minpix pixels, recenter next window (`rightx_current` or `leftx_current`) on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:\n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        try:\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        except ValueError:\n",
    "            # Avoids an error if the above is not implemented fully\n",
    "            pass\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        return leftx, lefty, rightx, righty\n",
    "\n",
    "    def measure_curvature_real(self,leftx, lefty, rightx, righty):\n",
    "        \n",
    "        #Fit a second order polynomial to each using `np.polyfit` in meters\n",
    "        left_fit_cr = np.polyfit(self.ym_per_pix*lefty, self.xm_per_pix*leftx, 2)\n",
    "        right_fit_cr = np.polyfit(self.ym_per_pix*righty, self.xm_per_pix*rightx, 2)\n",
    "        \n",
    "        #defining the y-value where we want radius of curvature in meters\n",
    "        y_eval = self.Image.shape[0] * self.ym_per_pix\n",
    "\n",
    "        #calculating of R_curve (radius of curvature) in meters\n",
    "        left_curverad = ((1+((2*left_fit_cr[0]*y_eval)+left_fit_cr[1])**2)**(3//2))/(2*left_fit_cr[0])  #calculating for the left line \n",
    "        right_curverad = ((1+((2*right_fit_cr[0]*y_eval)+right_fit_cr[1])**2)**(3//2))/(2*right_fit_cr[0])  #calculating for the right line \n",
    "        \n",
    "        '''Since the radius of curvature value will large for a straight line,\n",
    "           So if the value is greater than 4000 it is set as zero'''\n",
    "        if((abs(left_curverad) > 4000) or (abs(right_curverad) > 4000)):\n",
    "            #set left curvature value to 0\n",
    "            left_curverad = 0\n",
    "            #set right curvature value to 0\n",
    "            right_curverad = 0\n",
    "            \n",
    "        return left_curverad, right_curverad\n",
    "\n",
    "    def calculate_vehicle_position(self,left_fitx,right_fitx):\n",
    "        #calculate the mid pix of the image\n",
    "        image_mid = self.Image.shape[1]/2\n",
    "        #defining the y-value where we want radius of curvature\n",
    "        y_eval = self.Image.shape[0]\n",
    "\n",
    "        #calculating of R_curve (radius of curvature)\n",
    "        left_curverad = ((1+((2*left_fitx[0]*y_eval)+left_fitx[1])**2)**(3//2))/(2*left_fitx[0])  #calculating for the left line \n",
    "        right_curverad = ((1+((2*right_fitx[0]*y_eval)+right_fitx[1])**2)**(3//2))/(2*right_fitx[0])  #calculating for the right line\n",
    "\n",
    "        #calculating the vechicle postion\n",
    "        vehicle_position = (((left_curverad +(right_curverad-left_curverad))/2) - image_mid) \n",
    "        \n",
    "        #convert the vehicle postion from pixel to meters\n",
    "        vehicle_position = vehicle_position * self.xm_per_pix\n",
    "        \n",
    "        return np.round(vehicle_position, 2)\n",
    "    \n",
    "    def fit_polynomial(self):\n",
    "        # Find our lane pixels first\n",
    "        leftx, lefty, rightx, righty = self.find_lane_pixels()\n",
    "            \n",
    "        #Fit a second order polynomial to each using `np.polyfit` with values from the find_lane_pixels function\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "        # Generate y values for plotting lane\n",
    "        ploty = np.linspace(0, self.Image.shape[0]-1, self.Image.shape[0] )\n",
    "        \n",
    "        # Generate X values for plotting lane\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Calculate the radius of curvature in meters for both lane lines\n",
    "        left_curverad_real, right_curverad_real = self.measure_curvature_real(leftx, lefty, rightx, righty)                \n",
    "        \n",
    "        #check if both the readius of curvature is not equal zero\n",
    "        if((left_curverad_real != 0) and (right_curverad_real != 0)):\n",
    "            #calcualte the vehicle postion using the left and right radius of curvature\n",
    "            vehicle_position = self.calculate_vehicle_position(left_fit,right_fit)\n",
    "        else:\n",
    "            '''set the vehicle_position to zero, because both the left and \n",
    "               right radius are zero so it will be straight line'''\n",
    "            vehicle_position = 0\n",
    "            \n",
    "        #store the calculated values in Dictionary\n",
    "        value = {'ploty':ploty,\n",
    "                 'left_fitx':left_fitx,\n",
    "                 'right_fitx': right_fitx,\n",
    "                 'vehicle_position':vehicle_position,\n",
    "                 'left_curverad_real':np.round(left_curverad_real, 1),\n",
    "                 'right_curverad_real':np.round(right_curverad_real, 1),\n",
    "                 }\n",
    "\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625a709",
   "metadata": {},
   "source": [
    "# Image PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c66fdc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#directory of the input images\n",
    "imageDir = \"test_images/\"\n",
    "#directory in which the processed image must be saved\n",
    "imageOutputDir = \"output_images/\"\n",
    "\n",
    "#read all the image from the input directory for processing\n",
    "for filename in os.listdir(imageDir):\n",
    "    #split the file based on dot(.) which will be used for storing\n",
    "    filenames =filename.split('.')\n",
    "    \n",
    "    #read the image\n",
    "    orginal_image = mpimg.imread(imageDir+filename)\n",
    "\n",
    "    #create a object for Wrap Class\n",
    "    ImgWrap = Wrap()\n",
    "    \n",
    "    #undistort the original image\n",
    "    undist_image = undistortImage(orginal_image)\n",
    "\n",
    "    #create a object for ColourAndGradient Class\n",
    "    CG = ColourAndGradient(undist_image)\n",
    "\n",
    "    #apply Gradient and Colour fliteration over the undistorted image\n",
    "    binaryImage = CG.ApplyColourAndGradient()\n",
    "\n",
    "    #Wrap the binary image to top view(i.e. bird-eye view)\n",
    "    WrapImage = ImgWrap.perspectiveWarp(binaryImage)\n",
    "\n",
    "    #create a object for DetectLaneAndCurvature Class\n",
    "    DLC = DetectLaneAndCurvature(WrapImage)\n",
    "\n",
    "    #apply lane detection over the wrapped image to get the lane lines,curavature of line and vehicle postion\n",
    "    DLCValues= DLC.fit_polynomial()\n",
    "\n",
    "    # Create an image to draw the lane lines\n",
    "    binaryImage_zero = np.zeros_like(binaryImage)\n",
    "    color_warp = np.dstack((binaryImage_zero, binaryImage_zero, binaryImage_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([DLCValues['left_fitx'], DLCValues['ploty']]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([DLCValues['right_fitx'], DLCValues['ploty']])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    #Wrap the lane lines image back to original postion in the image\n",
    "    InvWrapImage= ImgWrap.perspectiveWarpInv(color_warp)\n",
    "\n",
    "    #super impose the highlighted lane lines over original image\n",
    "    result = weighted_img(InvWrapImage,orginal_image)\n",
    "\n",
    "    #check the numerical value of the vehicle position and change into readable formate\n",
    "    vehicle_position = ''\n",
    "    if(DLCValues['vehicle_position'] < 0):\n",
    "        vehicle_position = str(abs(DLCValues['vehicle_position'])) + 'm left to center'\n",
    "    elif(DLCValues['vehicle_position'] > 0):\n",
    "        vehicle_position = str(DLCValues['vehicle_position']) + 'm right to center'\n",
    "    else:\n",
    "        vehicle_position = 'at the center'\n",
    "\n",
    "    #using the cv2.putText function to write over the image\n",
    "    cv2.putText(result,'Radius of Curavature Left '+str(DLCValues['left_curverad_real'])+'(m)',(20,50),0,1,(255,255,255),2)\n",
    "    cv2.putText(result,'Radius of Curavature Right '+str(DLCValues['right_curverad_real'])+'(m)',(20,90),0,1,(255,255,255),2)\n",
    "    cv2.putText(result,'Vehicle is '+ vehicle_position,(20,130),0,1,(255,255,255),2)\n",
    "    \n",
    "    #save the image in the output image directory\n",
    "    mpimg.imsave(imageOutputDir+filenames[0]+'_output.'+filenames[1],result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864fdcb",
   "metadata": {},
   "source": [
    "# Video PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c560dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pipeline(orginal_image):\n",
    "    #create a object for Wrap Class\n",
    "    ImgWrap = Wrap()\n",
    "    \n",
    "    #undistort the original image\n",
    "    undist_image = undistortImage(orginal_image)\n",
    "\n",
    "    #create a object for ColourAndGradient Class\n",
    "    CG = ColourAndGradient(undist_image)\n",
    "\n",
    "    #apply Gradient and Colour fliteration over the undistorted image\n",
    "    binaryImage = CG.ApplyColourAndGradient()\n",
    "\n",
    "    #Wrap the binary image to top view(i.e. bird-eye view)\n",
    "    WrapImage = ImgWrap.perspectiveWarp(binaryImage)\n",
    "\n",
    "    #create a object for DetectLaneAndCurvature Class\n",
    "    DLC = DetectLaneAndCurvature(WrapImage)\n",
    "\n",
    "    #apply lane detection over the wrapped image to get the lane lines,curavature of line and vehicle postion\n",
    "    DLCValues= DLC.fit_polynomial()\n",
    "\n",
    "    # Create an image to draw the lane lines\n",
    "    binaryImage_zero = np.zeros_like(binaryImage)\n",
    "    color_warp = np.dstack((binaryImage_zero, binaryImage_zero, binaryImage_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([DLCValues['left_fitx'], DLCValues['ploty']]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([DLCValues['right_fitx'], DLCValues['ploty']])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    #Wrap the lane lines image back to original postion in the image\n",
    "    InvWrapImage= ImgWrap.perspectiveWarpInv(color_warp)\n",
    "\n",
    "    #super impose the highlighted lane lines over original image\n",
    "    result = weighted_img(InvWrapImage,orginal_image)\n",
    "\n",
    "    #check the numerical value of the vehicle position and change into readable formate\n",
    "    vehicle_position = ''\n",
    "    if(DLCValues['vehicle_position'] < 0):\n",
    "        vehicle_position = str(abs(DLCValues['vehicle_position'])) + 'm left to center'\n",
    "    elif(DLCValues['vehicle_position'] > 0):\n",
    "        vehicle_position = str(DLCValues['vehicle_position']) + 'm right to center'\n",
    "    else:\n",
    "        vehicle_position = 'at the center'\n",
    "\n",
    "    #using the cv2.putText function to write over the image\n",
    "    cv2.putText(result,'Radius of Curavature Left '+str(DLCValues['left_curverad_real'])+'(m)',(20,50),0,1,(255,255,255),2)\n",
    "    cv2.putText(result,'Radius of Curavature Right '+str(DLCValues['right_curverad_real'])+'(m)',(20,90),0,1,(255,255,255),2)\n",
    "    cv2.putText(result,'Vehicle is '+ vehicle_position,(20,130),0,1,(255,255,255),2)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7ad08",
   "metadata": {},
   "source": [
    "# video1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3da62ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video project_video_output.mp4.\n",
      "Moviepy - Writing video project_video_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready project_video_output.mp4\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(12,17)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "video_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06f0c6",
   "metadata": {},
   "source": [
    "# video2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b09e0546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video challenge_video_output.mp4.\n",
      "Moviepy - Writing video challenge_video_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready challenge_video_output.mp4\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'challenge_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(12,17)\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "video_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81367f",
   "metadata": {},
   "source": [
    "# video3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5742034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video harder_challenge_video_output.mp4.\n",
      "Moviepy - Writing video harder_challenge_video_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready harder_challenge_video_output.mp4\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'harder_challenge_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(12,17)\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "video_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97088061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
